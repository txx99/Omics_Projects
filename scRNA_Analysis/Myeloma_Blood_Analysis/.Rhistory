sp<- integer(c(1, 2, 3)
)
sp<-c(1, 2, 3)
typeof(sp)
sp<- integer(sp)
sp<- as.integer(sp)
typeof(sp)
library(car)
library(MASS)
library(rstatix)
library(datasets)
sessionInfo()  # R version and package version info
# Use typeof() or class() to check the objects that are part of the list test_objects
test_objects <- list(c(27, 34.5, 1.2, 100),
3L,
c(1, 2, 3, 4),
c(1L, 2L, 3L, 4L),
TRUE,
c(TRUE, FALSE, TRUE, FALSE),
c("Hello", "there"),
"python string",
factor(c("early", "middle", "late", "late", "early")))
typeof(test_objects)
typeof(test_objects[[1]])
typeof(test_objects[[2]])
typeof(test_objects[2])
typeof(test_objects[[2]])
typeof(test_objects)
typeof(test_objects[[1]])
typeof(test_objects[[2]])
typeof(test_objects[[6]])
typeof(test_objects[[9])
typeof(test_objects[[9]])
# mean, if given a list, will only take the mean of the first object
mean(4.9, 11, 3)
mean(c(4.9, 11, 3))
test_vector <- c(4.9, 26, 2025, 10.2)
# mean, if given a list, will only take the mean of the first object
mean(test_vector)
mean(4.9, 11, 3)
# if given a vector item, will take the eman of the entire vector
mean(c(4.9, 11, 3))
range(iris$Sepal.Length)
range(iris$Sepal.Width)
range(iris$Sepal.Length)
range(iris$Sepal.Width)
apply(iris, 2, range)
apply(iris[, 1:4], 2, range)
apply(iris, 2, range)
apply(iris[, 1:4], 2, range)
```{r}
```{r}
```{r}
```{r}
range(iris$Sepal.Length)
range(iris$Sepal.Width)
```{r}
```{r}
library(car)
library(MASS)
library(rstatix)
library(datasets)
sessionInfo()  # R version and package version info
# Use typeof() or class() to check the objects that are part of the list test_objects
test_objects <- list(c(27, 34.5, 1.2, 100),
3L,
c(1, 2, 3, 4),
c(1L, 2L, 3L, 4L),
TRUE,
c(TRUE, FALSE, TRUE, FALSE),
c("Hello", "there"),
"python string",
factor(c("early", "middle", "late", "late", "early")))
typeof(test_objects)
typeof(test_objects[[1]])
typeof(test_objects[[2]])
typeof(test_objects[[9]])
# Try out the next few functions with the numbers 4.9, 26, 2025, 10.2
# If you need more information about a function like min, try running ?min
test_vector <- c(4.9, 26, 2025, 10.2)
# mean, if given a list, will only take the mean of the first object
mean(4.9, 11, 3)
# if given a vector item, will take the eman of the entire vector
mean(c(4.9, 11, 3))
mean(test_vector)
range(iris$Sepal.Length)
range(iris$Sepal.Width)
range(iris$Sepal.Length)
range(iris$Sepal.Width)
#list
?lapply
#vector
?sapply
#dataframe
?apply
apply(iris, 2, range)
apply(iris[, 1:4], 2, range)
# parameter df;
# also gives us counts of different categoricals
summary(iris)
quantile(iris$Sepal.Length)
# Try out the correlation function with the "women" dataset and check if it matches the results described later
head(women)
summary(women)
# Are the assumptions of the test met?
plot(women$height, women$weight)
shapiro.test(women$height)
shapiro.test(women$weight)
# Try out the correlation function with the "women" dataset and check if it matches the results described later
head(women)
summary(women)
# Are the assumptions of the test met?
plot(women$height, women$weight)
shapiro.test(women$height)
shapiro.test(women$weight)
# Run cor.test()
# Run cor.test()
cor.test(women)
# Run cor.test()
cor.test(women$height, women$weight)
# Q. i want a more exact p-value; how do i get it from the output of cor.test?
?cor.test
# outputs  a list >> save the output list, then extract exact data points we want
cor_out<- cor.test(women$height, women$weight, method = 'pearson')
cor_out$p.value
cor_out$null.value
cor_out$estimate
cor_out$p.value
cor_out$null.value
cor_out$estimate
print(signif(cor_out$p.value), 4)
print(signif(cor_out$estimate), 4)
# outputs  a list >> save the output list, then extract exact data points we want
cor_out<- cor.test(women$height, women$weight, method = 'spearman')
cor_out$p.value
cor_out$null.value
cor_out$estimate
cor_out$p.value
cor_out$null.value
cor_out$estimate
# outputs  a list >> save the output list, then extract exact data points we want
cor_out<- cor.test(women$height, women$weight, method = 'pearson')
cor_out$p.value
cor_out$null.value
cor_out$estimate
cor_out$p.value
t.test(beaver2$temp[beaver2$activ==0], beaver2$temp[beaver2$activ==1], var.equal = TRUE)
u_out<- wilcox.test(temp ~ activ, data = beaver2)
u_out$p.value
u_out$p.value
u_out$statistic
?anorexia
?anorexia
# == paired data set of patients before and after
summary(anorexia)
dim(anorexia)
head(anorexia)
table(anorexia)
# Try out the various paired t-tests using the "Prewt" and "Postwt" columns from the "anorexia" dataset and check if it matches the results described later
# Make sure the paired t-test is appropriate (differences are normally distributed)
# == paired data set of patients before and after
summary(anorexia)
dim(anorexia)
head(anorexia)
table(anorexia)
head(anorexia)
tail(anorexia)
# Try out the various paired t-tests using the "Prewt" and "Postwt" columns from the "anorexia" dataset and check if it matches the results described later
t.test(anorexia$Prewt, anorexia$Postwt, paired=TRUE)
shapiro.test(anorexia$Prewt_mod - anorexia$Postwt_mod)
shapiro.test(anorexia$Prewt - anorexia$Postwt)
# Try out the next few tests using "weight" and "Diet" in the "ChickWeight" dataset
chick_aov<- aov(weight~Diet, data=ChickWeight)
summary(chick_aov)
chick_aov<- aov(weight~Diet, data=ChickWeight)
summary(chick_aov)
plot(chick_aov)  # For the first plot, we are looking for a normal distribution of variables; for the second plot, we are looking for alignment with the dotted line
shapiro.test(chick_aov$residuals)
leveneTest(weight ~ Diet, data = ChickWeight)
kruskal.test(weight ~ Diet, data = ChickWeight)
dunn_test(weight ~ Diet, data = ChickWeight, p.adjust.method = "bonferroni")
# Try out the next few tests using  the "Orange" dataset
head(Orange)
tail(Orange)
dim(Orange)
summary(Orange)
orange_aov <- anova_test(data = Orange, dv = circumference, wid = Tree, within = age)
get_anova_table(orange_aov)
get_anova_table(orange_aov)
# pairwise comparisons
pairwise_t_test(
circumference ~ age, paired = TRUE,
p.adjust.method = "bonferroni",
data = Orange)
# Use the survey dataset for the last few tests
head(sirvey)
# Use the survey dataset for the last few tests
head(survey)
summary(sirvey)
summary(survey)
survey_table
survey_table<- table(survey$Smoke, survey$Exer)
survey_table
chisq.test(survey_table)
# Warning: Chi-squared approximation may be incorrect
# > bc we have v small sample size >> can group them
survey$Smoke_grouped<- ifelse(survey$Smoke=='Never', 'Never', 'Smokes')
head(survey)
smoke_grouped_table<- table(survey$Smoke_grouped, survey$Exer)
chisq.test(smoke_grouped_table)
chisq.test(smoke_grouped_table)
fisher.test(survey_table)
fisher.test(smoke_grouped_table)
chisq.test(survey_table)
fisher.test(survey_table)
fisher.test(smoke_grouped_table)
?wilcox.test
library(tidyverse)
library(ggfortify)
library(MASS)
library(car)
library(rstatix)
library(survival)
library(DESeq2)  # BiocManager::install("DESeq2")
library(pheatmap)
sessionInfo()
Leinhardt$oil_mod <- ifelse(Leinhardt$oil == "no", 0, 1)
# Explore the Leinhardt dataset
head(Leinhardt)
Leinhardt$oil_mod <- ifelse(Leinhardt$oil == "no", 0, 1)
# Explore the Leinhardt dataset
head(Leinhardt)
summary(Leinhardt)
# Run glm() and summary() here
gml_oil_inf <- glm(oil_mod~infant, Leinhardt, family=binomial)
summary(gml_oil_inf)
# Transform some of the values for interpretation
Leinhardt$oil_mod <- ifelse(Leinhardt$oil == "no", 0, 1)
# Explore the Leinhardt dataset
head(Leinhardt)
summary(Leinhardt)
dim(Leinhardt)
# hist()
# Run glm() and summary() here
gml_oil_inf <- glm(oil_mod~infant, Leinhardt, family=binomial)
summary(gml_oil_inf)
# Transform some of the values for interpretation
# reverse of log oggds
plogis(gml_oil_inf$coefficients)
# Transform some of the values for interpretation
# reverse of log oggds
plogis(gml_oil_inf$coefficients)
# Run glm() and summary() here
glm_oil_inf <- glm(oil_mod~infant, Leinhardt, family=binomial)
summary(glm_oil_inf)
# Transform some of the values for interpretation
# reverse of log oggds
plogis(glm_oil_inf$coefficients)
#want intercept + inflection point
-glm_oil_infant$coefficients[1] / -glm_oil_inf$coefficients[2]
# Run glm() and summary() here
glm_oil_inf <- glm(oil_mod~infant, Leinhardt, family=binomial)
summary(glm_oil_inf)
# Transform some of the values for interpretation
# reverse of log oggds
plogis(glm_oil_inf$coefficients)
#want intercept + inflection point
-glm_oil_inf$coefficients[1] / -glm_oil_inf$coefficients[2]
Seatbelts <- as.data.frame(Seatbelts)
Seatbelts$law <- factor(Seatbelts$law)
# Other than head, what are some other ways to explore the Seatbelts dataset?
head(Seatbelts)
summary(Seatbelts)
dim(Seatbelts)
table(Seatbelts)
# Other than head, what are some other ways to explore the Seatbelts dataset?
head(Seatbelts)
summary(Seatbelts)
dim(Seatbelts)
table(Seatbelts)
# Let's check quickly: how are kms and DriversKilled related approximately?
plot(Seatbelts$kms, Seatbelts$DriversKilled)
# Run lm() and summary() here
lm(kms~DriversKilled, Seatbelts)
head(lung)
summary(lung)
# lung <- lung %>% mutate(status_new = case_when(status == "1" ~ 0, status == "2" ~ 1))  # tidyverse way
lung$status_new <- ifelse(lung$status == "1", 0, 1) # base R way
table(lung$sex)
head(lung)
# lung <- lung %>% mutate(status_new = case_when(status == "1" ~ 0, status == "2" ~ 1))  # tidyverse way
lung$status_new <- ifelse(lung$status == 1, 0, 1) # base R way
table(lung$sex)
head(lung)
table(lung$status_new)
head(lung)
?lung
# Run Surv() and look at the first 10 observations
# first we make a survival package
# Surv(time= , event = )
lung_surv <- Surv(time= lung$time, event = lung$status_new)
lung_surv[1:10]
# Run survfit() and investigate the structure of the output with str()
?survfit
# Run survfit() and investigate the structure of the output with str()
?survfit
survfit(lung_surv~1)
fit <- survfit(Surv(time, status_new) ~1, data = lung)
survfit(lung_surv~1)
fit <- survfit(Surv(time, status_new) ~1, data = lung)
fit
survfit(lung_surv~1)
fit
str(fit)
str(Seatbelts)
# Use plot()
plot(fit)
# Run summary()
# You can get the documentation with "?summary.survfit"
?summary.survfit
summary(fit, times=c(365, 3650))
summary(fit, times=c(365, 3650), extend = TRUE)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
coxph(sex ~ time, fit)
lungmf_surv <- coxph(Surv(time, status_new) ~sex, data = lung)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
coxph(sex ~ time, fit)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
#coxph(sex ~ time, fit)
lungmf_surv <- coxph(Surv(time, status_new) ~sex, data = lung)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
#coxph(sex ~ time, fit)
lungmf_surv <- coxph(Surv(time, status_new) ~sex, data = lung)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
coxph(sex ~ time, fit)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
#coxph(sex ~ time, fit)
lungmf_surv <- coxph(Surv(time, status_new) ~sex, data = lung)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
# coxph(sex ~ time, fit)
lungmf_surv <- coxph(Surv(time, status_new) ~sex, data = lung)
summary(lungmf_surv)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
coxph(sex ~ time, lung)
# Run coxph() and summary()
# proportional hazards regression; differences bw groups
# coxph(sex ~ time, lung) # NOPE wont work, want differneces ni survival over time by gender, so 3 variables we're looking at
lungmf_surv <- coxph(Surv(time, status_new) ~sex, data = lung)
summary(lungmf_surv)
# Repeat previous analysis with sex as and additional variable
fitMF <- survfit(Surv(time, status) ~ sex, data = lung)
plot(fitMF, col = c("blue", "red"))
fitMF
head(Pottery)
dim(Pottery)
str(Pottery)
head(Pottery)
str(Pottery)
summary(Pottery)
# Subset and scale Pottery
pottery_sub <- Pottery[, -1]
head(pottery_sub)
pottery_scaled <- scale(pottery_sub)
cat("\n")
cat("Unscaled variances:\n")
apply(pottery_sub, 2, var)
cat("Scaled variances:\n")
apply(pottery_scaled, 2, var)
# Subset and scale Pottery
pottery_sub <- Pottery[, -1]
head(pottery_sub)
pottery_scaled <- scale(pottery_sub)
#each col is different elements
cat("\n")
cat("Unscaled variances:\n")
apply(pottery_sub, 2, var)
cat("Scaled variances:\n")
apply(pottery_scaled, 2, var)
# Run prcomp() and summary()
pc_pottery<- prcomp(pottery_scaled)
pc_pottery
summary(pc_pottery)
# $rotation contains the contributions of each element to the principal components (also called loadings)
pc_pottery$rotation
poc_pottery$x
pc_pottery$x
autoplot(pc_pottery, data = Pottery, colour = "Site",
loadings = TRUE,
loadings.label = TRUE,
loadings.colour = "blue",
loadings.label.size = 7) + theme_bw()
memory.limit()
memory.limit(size=3000)
memory.limit()
source("C:/Users/liv_u/Desktop/GitHub/Omics_Projects/scRNA_Analysis/Myeloma_Blood_Analysis/Script/main.R", echo = TRUE)
# Cell type identification//DEA (FindAllMarkers()) ----
sdf<-FindAllMarkers(sdf) #cluster-based
install.packages('devtools')
devtools::install_github('immunogenomics/presto')
install.packages(Rtools)
install.packages('Rtools')
